{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서는 배열(array)이나 행렬(matrix)과 매우 유사한 특수 자료구조로, PyTorch에서는 텐서를 사용하여 모델의 입력과 출력뿐만 아니라 모델의 매개변수를 encode하기도 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 데이터로부터 바로 생성\n",
    "data = [[1,2],[3,4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) NumPy 배열로부터 생성\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "tensor([[0.8932, 0.1250],\n",
      "        [0.5831, 0.3959]])\n"
     ]
    }
   ],
   "source": [
    "# 3) 다른 텐서로부터 생성: 명시적으로 override 하지 않는다면 인자로 주어진 텐서의 shape, datatype 유지\n",
    "x_ones = torch.ones_like(x_data)\n",
    "print(x_ones)\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # dtype override\n",
    "print(x_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4312, 0.1350, 0.5537],\n",
      "        [0.7755, 0.1786, 0.4219]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 4) 무작위 또는 상수 값 사용\n",
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(rand_tensor)\n",
    "print(ones_tensor)\n",
    "print(zeros_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서의 속성(attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서의 속성(attribute)이란 shape, datatype, 그리고 어느 장치에 해당 텐서가 저장되는지를 나타낸다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.shape = torch.Size([3, 4])\n",
      "tensor.dtype = torch.float32\n",
      "tensor.device = device(type='cpu')\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "print(f'{tensor.shape = }')\n",
    "print(f'{tensor.dtype = }')\n",
    "print(f'{tensor.device = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 연산(operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transposing, indexing, slicing, 수학 계산, 선형 대수, random sampling 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.device = device(type='mps', index=0)\n"
     ]
    }
   ],
   "source": [
    "# GPU Setting\n",
    "if platform.system() == 'Darwin': # MacOS\n",
    "    if torch.backends.mps.is_built() and torch.backends.mps.is_available():\n",
    "        # device = torch.device(\"mps\")\n",
    "        tensor = tensor.to('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')\n",
    "\n",
    "print(f'{tensor.device = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy 변환 (Bridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPU 상의 텐서와 NumPy 배열은 메모리 공간을 공유한다 == 하나를 변경하면 다른 하나도 변경된다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = tensor([1., 1., 1., 1., 1.])\n",
      "n = array([1., 1., 1., 1., 1.], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f'{t = }')\n",
    "\n",
    "n = t.numpy()\n",
    "print(f'{n = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = tensor([2., 2., 2., 2., 2.])\n",
      "n = array([2., 2., 2., 2., 2.], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f'{t = }')\n",
    "print(f'{n = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n",
      "n = array([3., 3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 2, out=n)\n",
    "print(f'{t = }')\n",
    "print(f'{n = }')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
