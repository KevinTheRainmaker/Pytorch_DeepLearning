{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: <a href='https://arxiv.org/abs/1803.08494'>Group Normalization</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Normalization(GN)은 Layer Normalization에 이어, 배치 사이즈에 영향을 많이 받는 Batch Normalization(BN)의 한계를 극복하기 위해 제안된 정규화 기법이다. 피쳐들을 그룹으로 정규화하는 방식을 취하며, 이는 <a href='https://en.wikipedia.org/wiki/Scale-invariant_feature_transform'>SIFT</a>나 <a href='https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients'>HOG</a>와 같은 고전적인 특징 추출 방법에서 특징을 추출할 때 지역적 패치 혹은 블록(Block) 단위로 정규화가 되는 것에서 고안되었다.\n",
    "\n",
    "GN은 채널 축을 그룹으로 나누어 각 그룹 내에서 평균과 분산을 계산하여 정규화한다. 이는 입력 채널을 G개의 그룹으로 나누어 각 그룹에 대해 정규화하는 방식으로 배치 크기에 관계없이 항상 안정적인 정규화 효과를 발휘한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 $X\\in \\mathbb{R}^{N\\times C\\times H\\times W}$와 그룹 수 $G$에 대해 다음과 같이 계산된다.\n",
    "\n",
    "1. 각 그룹 내 평균 $\\mu_g$와 분산 $\\sigma^2_g$ 계산\n",
    "$$\n",
    "\\mu_g = {1\\over C/G \\cdot H \\cdot W}\\Sigma_{c\\in\\mathcal{G}_g}\\Sigma^{H-1}_{h=0}\\Sigma^{W-1}_{w=0}X_{n,c,h,w}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma^2_g = {1\\over C/G \\cdot H \\cdot W}\\Sigma_{c\\in\\mathcal{G}_g}\\Sigma^{H-1}_{h=0}\\Sigma^{W-1}_{w=0}(X_{n,c,h,w}-\\mu_g)^2\n",
    "$$\n",
    "\n",
    "2. 정규화\n",
    "\n",
    "$$\n",
    "\\hat{X} = {X_{n,c,h,w}-\\mu_g\\over \\sqrt{\\sigma^2_g + \\epsilon}}\n",
    "$$\n",
    "\n",
    "3. 스케일링 및 쉬프트\n",
    "$$\n",
    "GN(X) = \\gamma {X_{n,c,h,w}-\\mu_g\\over \\sqrt{\\sigma^2_g + \\epsilon}} + \\beta\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupNorm(nn.Module):\n",
    "    '''\n",
    "    groups: 피쳐를 나누는 그룹 수\n",
    "    channels: 채널 수\n",
    "    eps: 엡실론\n",
    "    affine: 스케일링 및 시프트 적용 여부 불리언\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, groups: int, channels: int, *,\n",
    "                 eps: float = 1e-5, affine: bool = True):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert channels % groups == 0, \"Number of channels should be evenly divisible by the number of groups\"\n",
    "        self.groups = groups\n",
    "        self.channels = channels\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "        \n",
    "        if self.affine:\n",
    "            self.gamma = nn.Parameter(torch.ones(channels))\n",
    "            self.beta = nn.Parameter(torch.zeros(channels))\n",
    "        \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x.shape = [batch_size, channels, *]\n",
    "        x_shape = x.shape\n",
    "        \n",
    "        batch_size = x_shape[0]\n",
    "        assert self.channels == x_shape[1]\n",
    "        \n",
    "        # reshape into [batch_size, groups, n]\n",
    "        x = x.view(batch_size, self.groups, -1)\n",
    "        \n",
    "        # calculate mean and variance across last dimension\n",
    "        mean = x.mean(dim=[-1], keepdim=True)\n",
    "        mean_x2 = (x ** 2).mean(dim=[-1], keepdim=True)\n",
    "        \n",
    "        var = mean_x2 - (mean ** 2)\n",
    "        \n",
    "        # normalize\n",
    "        x_norm = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        \n",
    "        if self.affine:\n",
    "            # channel-wise\n",
    "            x_norm = x_norm.view(batch_size, self.channels, -1)\n",
    "            x_norm = self.gamma.view(1,-1,1) * x_norm + self.beta.view(1,-1,1)\n",
    "            \n",
    "        x_norm = x_norm.view(x_shape) # to original shape\n",
    "        \n",
    "        return x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test():\n",
    "    x = torch.randn([2,6,2,4]) # B C H W\n",
    "    print(f'original input: {x})')\n",
    "    \n",
    "    gn = GroupNorm(2,6)\n",
    "    x = gn(x)\n",
    "    \n",
    "    print(f'normalized input: {x}')\n",
    "    print(f'{gn.gamma.shape = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original input: tensor([[[[-3.1875e-01, -2.5255e+00, -1.9157e+00,  1.4343e-01],\n",
      "          [ 1.0294e+00,  1.4238e+00, -9.5062e-01, -1.2318e+00]],\n",
      "\n",
      "         [[ 9.9617e-01, -1.5139e+00,  8.5035e-01,  5.4831e-01],\n",
      "          [-1.0538e+00,  6.6934e-02,  3.2912e-01,  1.8479e+00]],\n",
      "\n",
      "         [[-1.5556e-03, -1.0585e-01, -1.2116e+00,  1.1413e+00],\n",
      "          [-3.0255e-01, -1.6866e-01,  1.1033e+00,  1.8413e+00]],\n",
      "\n",
      "         [[ 1.3062e+00, -1.3857e+00, -1.3622e+00,  2.0083e-02],\n",
      "          [-1.1508e+00, -1.8117e+00, -1.7821e-01,  5.5125e-01]],\n",
      "\n",
      "         [[ 6.9868e-01,  1.3340e+00, -1.9481e+00,  4.0271e-01],\n",
      "          [-1.1449e-01,  1.0895e+00,  2.4716e-01, -9.2342e-01]],\n",
      "\n",
      "         [[-6.5360e-02, -4.9357e-01,  1.0296e+00, -8.0111e-01],\n",
      "          [ 1.3396e+00, -6.0696e-01,  1.2484e+00,  2.1670e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2001e-01, -5.0902e-02, -7.1455e-01,  3.6899e-01],\n",
      "          [ 3.1756e-01,  2.8267e-01, -2.1198e-01,  1.8537e-01]],\n",
      "\n",
      "         [[-5.1675e-01, -6.5196e-01,  7.1314e-01, -2.1672e-01],\n",
      "          [-6.9847e-01,  5.3925e-01, -3.4984e-01,  1.0103e+00]],\n",
      "\n",
      "         [[-3.9253e-01,  1.4861e+00, -1.4683e+00, -1.0777e+00],\n",
      "          [-3.0067e-01, -1.6738e-01,  7.8220e-01,  2.1861e+00]],\n",
      "\n",
      "         [[-1.4288e+00, -7.4849e-01,  6.7502e-02, -1.2701e+00],\n",
      "          [-9.5590e-01, -1.5354e+00, -3.6008e-01,  4.8330e-01]],\n",
      "\n",
      "         [[ 2.7243e-01,  1.2010e+00,  1.9882e+00,  8.1052e-01],\n",
      "          [-1.3494e+00,  8.0990e-01,  1.1974e+00,  1.2993e+00]],\n",
      "\n",
      "         [[-1.7315e+00,  1.3309e+00,  1.6886e-01,  6.7761e-01],\n",
      "          [-6.5121e-01,  1.2563e+00,  1.2240e-01, -1.2737e+00]]]]))\n",
      "normalized input: tensor([[[[-2.7622e-01, -2.1834e+00, -1.6564e+00,  1.2321e-01],\n",
      "          [ 8.8886e-01,  1.2297e+00, -8.2229e-01, -1.0653e+00]],\n",
      "\n",
      "         [[ 8.6016e-01, -1.3091e+00,  7.3413e-01,  4.7310e-01],\n",
      "          [-9.1144e-01,  5.7095e-02,  2.8368e-01,  1.5962e+00]],\n",
      "\n",
      "         [[-2.0949e-03, -9.2232e-02, -1.0479e+00,  9.8556e-01],\n",
      "          [-2.6222e-01, -1.4651e-01,  9.5274e-01,  1.5906e+00]],\n",
      "\n",
      "         [[ 1.3514e+00, -1.3181e+00, -1.2948e+00,  7.6025e-02],\n",
      "          [-1.0851e+00, -1.7405e+00, -1.2062e-01,  6.0276e-01]],\n",
      "\n",
      "         [[ 7.4896e-01,  1.3790e+00, -1.8758e+00,  4.5546e-01],\n",
      "          [-5.7424e-02,  1.1365e+00,  3.0121e-01, -8.5962e-01]],\n",
      "\n",
      "         [[-8.7063e-03, -4.3334e-01,  1.0771e+00, -7.3832e-01],\n",
      "          [ 1.3845e+00, -5.4579e-01,  1.2941e+00,  2.7100e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9939e-01, -1.1268e-01, -9.4532e-01,  4.1412e-01],\n",
      "          [ 3.4960e-01,  3.0583e-01, -3.1478e-01,  1.8376e-01]],\n",
      "\n",
      "         [[-6.9715e-01, -8.6679e-01,  8.4591e-01, -3.2073e-01],\n",
      "          [-9.2515e-01,  6.2774e-01, -4.8775e-01,  1.2187e+00]],\n",
      "\n",
      "         [[-5.4130e-01,  1.8157e+00, -1.8911e+00, -1.4010e+00],\n",
      "          [-4.2605e-01, -2.5882e-01,  9.3256e-01,  2.6940e+00]],\n",
      "\n",
      "         [[-1.3264e+00, -7.0181e-01,  4.7399e-02, -1.1807e+00],\n",
      "          [-8.9224e-01, -1.4243e+00, -3.4519e-01,  4.2917e-01]],\n",
      "\n",
      "         [[ 2.3555e-01,  1.0881e+00,  1.8109e+00,  7.2961e-01],\n",
      "          [-1.2535e+00,  7.2903e-01,  1.0848e+00,  1.1783e+00]],\n",
      "\n",
      "         [[-1.6043e+00,  1.2074e+00,  1.4046e-01,  6.0757e-01],\n",
      "          [-6.1249e-01,  1.1389e+00,  9.7799e-02, -1.1840e+00]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "gn.gamma.shape = torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    _test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
